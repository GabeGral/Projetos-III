---
output: 
  pdf_document:
    keep_tex: true
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = T, echo = FALSE, tidy = TRUE, tidy.opts = list(width.cutoff = 60), warning = T)
```

```{r, include=FALSE}
library(tidyverse)
library(stargazer)
library(caret)
library(glmnet)
library(knitr)
```

```{r}
set.seed(1444)
```

```{r}
tidy_data = read_rds("tidy_data")
X = tidy_data[[1]]
Y = tidy_data[[2]]
X_test = tidy_data[[3]]
Y_test = tidy_data[[4]]
```


# Logit


O primeiro modelo utilizado foi o Logit com penalização do tipo Lasso (isto é, penalizando o valor absoluto dos coeficientes).

O parâmetro de penalização $\lambda$ foi escolhido por um 10-fold cross-validation.

```{r, eval = F}
lambdas = append(0, 10^seq(-5, 5, 0.25))
#plot(lambdas)
logit.cv = cv.glmnet(x = X, y = Y, family = "binomial",
                     type.measure = "class", nfolds = 10,
                     standardize = T, lambda = lambdas, alpha = 1)
plot(logit.cv, main = "Resultado do cross-validation")
#cbind(logit.cv$lambda, logit.cv$cvm)
#paste("melhor lambda: ", logit.cv$lambda.min)
#print(logit.cv)
```

```{r, fig.cap= "Resultado do cross-validation"}
#dando um zoom - para pegar um lambda mais preciso

lambdas = append(0, 10^seq(-5, 1, 0.1))
#plot(lambdas)
logit.cv = cv.glmnet(x = X, y = Y, family = "binomial",
                     type.measure = "class", nfolds = 10,
                     standardize = T, lambda = lambdas, alpha = 1)
plot(logit.cv)
#cbind(logit.cv$lambda, logit.cv$cvm)
#paste("melhor lambda: ", logit.cv$lambda.min)
#print(logit.cv)
```

O melhor valor para o $\lambda$ foi `r logit.cv$lambda.min`.

```{r}
logit = glmnet(x = X, y = Y, family="binomial", alpha = 1,
                 standardize = T)
plot(logit, xvar = "lambda", label = TRUE)
abline(v = log(logit.cv$lambda.min), col="red", lwd=2, lty=2)
```

Coeficientes

```{r}
coef(logit, s = logit.cv$lambda.min)
```

olhando quais seriam os \textcolor{red}{20} coeficientes restants no processo ilustrado no grafico acima

```{r}
coef(logit, s = (exp(-4))) %>% as.matrix() %>%
  data.frame() %>%
  filter(s1 != 0)
```

## Modelo final Logit

O modelo final, portanto, foi o logit com penalização com o melhor lambda.

Aplicando este algoritmo na base de teste, temos:

**Confusion Matrix**

```{r}
logit = glmnet(x = X, y = Y, family="binomial", alpha = 1,
                 standardize = T, lambda = logit.cv$lambda.min)
y_pred = predict(logit,  newx = X_test, type = "class") 
confusionMatrix( data = as.factor(y_pred),
                 reference = Y_test)$table
  
accuracy = confusionMatrix( data = as.factor(y_pred), reference = Y_test)$overall[1]
```

A acurácia fora da amostra foi `r accuracy`.













